{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "\n",
    "import re\n",
    "from BCBio import GFF\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genes(run_name):\n",
    "    '''\n",
    "    Function for extracting genes corresponding to BUSCO hits.\n",
    "    Returns a SeqRecord object with one feature per BUSCO hit.\n",
    "    '''\n",
    "\n",
    "    file_tsv = open(\"../data/intermediate/run_\"+run_name+\"/full_table_\"+run_name+\".tsv\", 'r')\n",
    "\n",
    "    # Extract BUSCO IDs, start and end from table of hits into SeqRecord object, each BUSCO as a SeqFeature\n",
    "    busco_record = SeqRecord(seq='', id='hits')\n",
    "    for line in file_tsv.readlines():\n",
    "        hit = (re.search(r'(\\S*)\\s(Complete|Duplicated)\\s(\\S*)\\s(\\S*)\\s(\\S*)\\s\\S*', line))\n",
    "        if hit:\n",
    "            busco_record.features.append(SeqFeature(FeatureLocation(int(hit.group(4)), int(hit.group(5))), id=hit.group(1), type='gene', qualifiers={'contig': hit.group(3)}))\n",
    "\n",
    "    file_tsv.close()\n",
    "\n",
    "    # Match the BUSCOs to augustus predicted genes in gff file\n",
    "    gff_records = []\n",
    "    correct_genes = SeqRecord(seq='', id='correct_genes')\n",
    "    limit_infos = dict(\n",
    "            gff_type = [\"gene\"]) # Only want genes\n",
    "\n",
    "    for busco in busco_record.features:\n",
    "        filename = busco.id # gff filenames are [busco_id].out.[1-999]\n",
    "        i = 1\n",
    "        while True:\n",
    "            try:\n",
    "                file_gff = open(\"../data/intermediate/run_\"+run_name+\"/augustus_output/predicted_genes/\"+filename+\".out.\"+str(i))\n",
    "                for record in GFF.parse(file_gff, limit_info=limit_infos):\n",
    "                    gff_records.append(record)\n",
    "                i += 1\n",
    "            except: # Finished reading all files for that BUSCO\n",
    "                break\n",
    "\n",
    "    # Find augustus predicted genes from the gff that match BUSCOs\n",
    "    for rec in gff_records:\n",
    "        for hit in busco_record.features:\n",
    "            for feature in rec.features:\n",
    "                if hit.location.start-1 == feature.location.start and hit.location.end == feature.location.end: # For some reason start has 1 nt diff...\n",
    "                    feature.id = rec.id \n",
    "                    correct_genes.features.append(feature)\n",
    "                    break\n",
    "\n",
    "    file_gff.close()\n",
    "    return correct_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_mapped():\n",
    "    '''\n",
    "    Function used to extract only reads mapped to a reference.\n",
    "    Really slow, only used to minimize the reads dataset in special use cases\n",
    "    '''\n",
    "    pairedreads = pysam.AlignmentFile(\"allpaired2.bam\", \"wb\", template=samfile)\n",
    "    mapped_reads =[]\n",
    "\n",
    "    for read in samfile.fetch():\n",
    "        # Probably stupidly long if-statement\n",
    "        if read.is_read1 and not read.is_secondary and not read.is_unmapped and not read.mate_is_unmapped and read not in mapped_reads:\n",
    "            mapped_reads.append(read)\n",
    "            pairedreads.write(read)\n",
    "            print(read)\n",
    "            print(samfile.mate(read))\n",
    "            pairedreads.write(samfile.mate(read))\n",
    "\n",
    "    return mapped_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_paired_region(genes):\n",
    "    '''\n",
    "    Function for inferring paired library-type by looking at a regions corresponding to genes\n",
    "    '''\n",
    "        # Counters for the different lib-types   \n",
    "    libs = {\n",
    "        'fr_first': 0,\n",
    "        'fr_second': 0,\n",
    "        'rf_first': 0,\n",
    "        'rf_second': 0,\n",
    "        'ff_first': 0,\n",
    "        'ff_second': 0,\n",
    "        'undecided': 0\n",
    "    }\n",
    "    \n",
    "    for gene in genes.features:\n",
    "        contig = gene.id\n",
    "        start = int(gene.location.start)\n",
    "        stop = int(gene.location.end)\n",
    "        strand = gene.strand\n",
    "        reads = []\n",
    "        # Get reads mapped to a specific contig and in a sequence range\n",
    "        # TODO: Look into optimizing this step, only take a subset (1000ish) reads? \n",
    "        # samfile.mate is not made for high throughput\n",
    "        for read in samfile.fetch(contig, start, stop):\n",
    "            if not read.mate_is_unmapped and read.is_read1:\n",
    "                reads.append([read, samfile.mate(read)])\n",
    "\n",
    "        \n",
    "\n",
    "        # Check lib-type of reads \n",
    "        for read in reads:\n",
    "            first = read[0]\n",
    "            second = read[1]\n",
    "            try:\n",
    "                lib = ''\n",
    "                if not first.is_reverse:\n",
    "                    lib += 'f'\n",
    "                else: \n",
    "                    lib += 'r'\n",
    "                if not second.is_reverse:\n",
    "                    lib += 'f'\n",
    "                else: \n",
    "                    lib += 'r'\n",
    "                # Gene on sense strand\n",
    "                if strand == 1:\n",
    "                    if first.reference_start > second.reference_start:\n",
    "                        # Flip order of reads\n",
    "                        lib = lib[::-1]\n",
    "                        lib += '_first'\n",
    "                    elif first.reference_start < second.reference_start:\n",
    "                        lib += '_second'\n",
    "                    else:\n",
    "                        lib = 'undecided'\n",
    "                # Gene on antisense\n",
    "                elif strand == -1:\n",
    "                    if first.reference_start > second.reference_start:\n",
    "                        # Flip order of reads\n",
    "                        lib = lib[::-1]\n",
    "                        lib += '_second'\n",
    "                    elif first.reference_start < second.reference_start:\n",
    "                        lib += '_first'\n",
    "                    else:\n",
    "                        lib = 'undecided'\n",
    "                libs[lib] += 1\n",
    "            except: libs['undecided'] +=1 #Some reads missing start or end-values\n",
    "    \n",
    "    return libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_single_region(genes):\n",
    "    \"\"\"\n",
    "    Function for inferring library type of single-ended library types\n",
    "    Work in progress\n",
    "    \"\"\"\n",
    "    \n",
    "    libs = {\n",
    "        'f_first': 0,\n",
    "        'f_second': 0,\n",
    "        'r_first': 0,\n",
    "        'r_second': 0\n",
    "    }\n",
    "    \n",
    "    for gene in genes.features:\n",
    "        contig = gene.id\n",
    "        start = int(gene.location.start)\n",
    "        stop = int(gene.location.end)\n",
    "        strand = gene.strand\n",
    "        reads = []\n",
    "        # Get reads mapped to a specific contig and in a sequence range\n",
    "        # Slow, only take 1000 reads?\n",
    "        for read in samfile.fetch(contig, start, stop):\n",
    "            if not read.is_unmapped:\n",
    "                reads.append(read)\n",
    "                \n",
    "    \n",
    "    \n",
    "            # Check lib-type of reads \n",
    "        for read in reads:\n",
    "            try:\n",
    "                lib = ''\n",
    "                if not read.is_reverse:\n",
    "                    lib += 'f'\n",
    "                else: \n",
    "                    lib += 'r'\n",
    "                # TODO: Make sure firststrand and secondstrand are correctly assigned\n",
    "                if strand == 1:\n",
    "                    if first.reference_start > second.reference_start:\n",
    "                        lib = lib[::-1]\n",
    "                        lib += '_first'\n",
    "                    elif first.reference_start < second.reference_start:\n",
    "                        lib += '_second'\n",
    "                    else:\n",
    "                        lib = 'undecided'\n",
    "                elif strand == -1:\n",
    "                    if first.reference_start > second.reference_start:\n",
    "                        lib = lib[::-1]\n",
    "                        lib += '_second'\n",
    "                    elif first.reference_start < second.reference_start:\n",
    "                        lib += '_first'\n",
    "                    else:\n",
    "                        lib = 'undecided'\n",
    "                    libs[lib] += 1\n",
    "            except: libs['undecided'] +=1 # Some reads missing start or end-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result(lib_dict):\n",
    "    output = open('../data/output/result.txt', 'w+')\n",
    "    output.write(\"Results of library inferring: \\nLibrary type \\t Reads \\t Percent \\n\")\n",
    "    \n",
    "    total_reads = 0\n",
    "    for i in lib_dict:\n",
    "        total_reads += lib_dict[i]\n",
    "    \n",
    "    for i in lib_dict:\n",
    "        percent = '{:.1%}'.format(lib_dict[i]/total_reads)\n",
    "        output.write(\"%s \\t %d \\t %s\\n\" % (i, lib_dict[i], percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'human'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bam-file with mapped reads, needs to be sorted and indexed\n",
    "samfile = pysam.AlignmentFile(\"../data/intermediate/4_sorted.bam\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = extract_genes(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcl|NC_000001.11_cds_XP_016856338.1_1236\n"
     ]
    }
   ],
   "source": [
    "print(test.features[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = infer_paired_region(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fr_first': 160, 'fr_second': 0, 'rf_first': 0, 'rf_second': 4, 'ff_first': 0, 'ff_second': 0, 'undecided': 7}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
